{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "from math import floor, ceil\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset, TensorDataset\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Config Setup ####################################\n",
    "dataset = 'Dataset'\n",
    "config = {'min_recall_value': 0.5, 'AMI_correlation_threshold': 0.125, 'batch_size': 32, 'dropout': 0, 'layer_size': 128, 'num_layers': 3, 'lr': 0.0001, 'epochs': 9}\n",
    "\n",
    "# Size of the coarse position prior as a number of images\n",
    "coarse_prior_size = 75\n",
    "# The nominated minimum performance target as a decimal representing recall@1\n",
    "target_min_recall = config['min_recall_value']\n",
    "# The step size to take between coarse position priors\n",
    "step_size = 15\n",
    "\n",
    "# Percentage of data to train (both training and validation)\n",
    "train_percent = 0.5\n",
    "# Percentage of data assigned to each split (train, validation, test)\n",
    "split_vals = [0.3, 0.2, 0.5]\n",
    "\n",
    "############################## Load Previously Computed Data #########################\n",
    "# This data is computed previously in another piece of the code (if not uploaded yet, it will be shortly)\n",
    "coarse_prior_appearance_var = np.load('Path_To_Data')\n",
    "min_seq_len_for_target = np.load('Path_To_Data')\n",
    "min_seq_len_for_target = min_seq_len_for_target.squeeze()\n",
    "\n",
    "# This is just finding the indices to use for the data splits\n",
    "cutoff = int(train_percent*coarse_prior_appearance_var.shape[0])\n",
    "train =  int((train_percent-0.2)*coarse_prior_appearance_var.shape[0])\n",
    "valid = cutoff-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Definitions for the Model and Loss Term #################################\n",
    "class Basic_NN(nn.Module):\n",
    "    def __init__(self, input_ftrs, n_classes, layer_size, num_layers, dropout):\n",
    "        super(Basic_NN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.base_model = nn.Sequential(nn.Linear(in_features=input_ftrs, out_features=layer_size))\n",
    "        self.hidden = nn.ModuleList()\n",
    "        if self.num_layers > 1:\n",
    "            for k in range(self.num_layers-1):\n",
    "                self.hidden.append(nn.Sequential(nn.ReLU(), nn.Dropout(p=dropout), nn.Linear(in_features=layer_size, out_features=layer_size)))\n",
    "\n",
    "        self.output = nn.Sequential(nn.ReLU(), nn.Dropout(p=dropout), nn.Linear(in_features=layer_size, out_features=n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        y = self.base_model(x)\n",
    "        for layer in self.hidden:\n",
    "            y = layer(y)\n",
    "        y = self.output(y)\n",
    "\n",
    "        return y\n",
    "    \n",
    "class LeakyReLUMSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, pred, actual):\n",
    "        return torch.mean(F.leaky_relu(actual-pred)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Curate Correlated Features #############################################################\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# The threshold for the AMI scores to decide which features are most correlated with sequence length selection\n",
    "AMI_correlation_threshold = config['AMI_correlation_threshold']\n",
    "# The total number of features in the original VPR feature descriptors\n",
    "total_num_ftrs = coarse_prior_appearance_var.shape[1]\n",
    "\n",
    "# Scaled training split\n",
    "appearance_var_train = scaler.fit_transform(coarse_prior_appearance_var[0:train,:])\n",
    "\n",
    "# Computing the adjusted mutual information correlation between features and sequence length\n",
    "# in the training set\n",
    "AMI_score_train = []\n",
    "for i in range(0, total_num_ftrs, 1):\n",
    "    AMI_score_train.append(adjusted_mutual_info_score(appearance_var_train[:,i], min_seq_len_for_target[0:train]))\n",
    "\n",
    "# The indices of the features which have an AMI correlation with sequence length selection which is\n",
    "# above the selected threshold\n",
    "curated_ftr_idxs = np.where(np.array(AMI_score_train) > AMI_correlation_threshold)[0].astype(int)\n",
    "\n",
    "######################### Create Training and Testing Data ##################################################\n",
    "\n",
    "# Scaled and curated appearance variation feature vectors\n",
    "curated_appearance_var_train = scaler.fit_transform(coarse_prior_appearance_var[0:train,curated_ftr_idxs])\n",
    "curated_appearance_var_valid = scaler.transform(coarse_prior_appearance_var[train:cutoff:,curated_ftr_idxs])\n",
    "curated_appearance_var_test = scaler.transform(coarse_prior_appearance_var[cutoff::,curated_ftr_idxs])\n",
    "\n",
    "########################## Setup Model Parameters ##########################################################\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = config['batch_size']\n",
    "layer_size = config['layer_size']\n",
    "num_layers = config['num_layers']\n",
    "dropout = config['dropout']\n",
    "lr = config['lr']\n",
    "max_epoch_number = config['epochs']\n",
    "\n",
    "device = torch.device('cpu')\n",
    "num_train_batches = int(np.ceil(train / batch_size))\n",
    "\n",
    "######################### Load Datasets ###################################################################\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(curated_appearance_var_train).float(), torch.from_numpy(min_seq_len_for_target[0:train]))\n",
    "valid_dataset = TensorDataset(torch.from_numpy(curated_appearance_var_valid).float(), torch.from_numpy(min_seq_len_for_target[train:cutoff]))\n",
    "tester_dataset = TensorDataset(torch.from_numpy(curated_appearance_var_test).float(), torch.from_numpy(min_seq_len_for_target[cutoff::]))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True) #, shuffle=True\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "test_dataloader = DataLoader(tester_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "################################# Initialize Model ###############################################################\n",
    "\n",
    "model = Basic_NN(curated_ftr_idxs.shape[0], 1, layer_size, num_layers, dropout)\n",
    "model.train()\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "criterion = LeakyReLUMSE()\n",
    "\n",
    "def round_to_odd(output):\n",
    "    return 2 * torch.round(output / 2) + 1\n",
    "\n",
    "################################### Training ########################################################################\n",
    "print('Starting Training')\n",
    "# Run training\n",
    "epoch = 0\n",
    "iteration = 0\n",
    "valid_loss_value = 1\n",
    "patience_counter = 0\n",
    "old_valid_loss = float('inf')\n",
    "all_losses = []\n",
    "all_valid_losses = []\n",
    "all_median_seqs = []\n",
    "all_sect_succs = []\n",
    "while True:\n",
    "    model_result_all = []\n",
    "    targets_all = []\n",
    "    batch_losses = []\n",
    "    train_filenames = []\n",
    "    all_preds = []\n",
    "    for inputs, targets in train_dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        model_result = model(inputs).squeeze()\n",
    "        loss = criterion(model_result, targets.float().squeeze())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        batch_losses.append(loss.item())\n",
    "        model_result_all.extend(model_result.detach().cpu().numpy())\n",
    "        targets_all = targets_all + targets.cpu().numpy().tolist()\n",
    "        all_preds = all_preds + model_result.detach().cpu().numpy().tolist()\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_targets_all = []\n",
    "        valid_all_preds = []\n",
    "        valid_batch_losses = []\n",
    "        train_filenames = []\n",
    "        for inputs, targets in valid_dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            model_result = model(inputs).squeeze()\n",
    "            valid_loss = criterion(model_result.squeeze(), targets.float()) \n",
    "\n",
    "            valid_batch_losses.append(valid_loss.item())\n",
    "            valid_targets_all = valid_targets_all + targets.cpu().numpy().tolist()\n",
    "            valid_all_preds = valid_all_preds + model_result.detach().cpu().numpy().tolist()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_targets_all = []\n",
    "        test_all_preds = []\n",
    "        for inputs, targets in test_dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            model_result = model(inputs).squeeze()\n",
    "            test_targets_all = test_targets_all + targets.cpu().numpy().tolist()\n",
    "            try:\n",
    "                test_all_preds = test_all_preds + model_result.detach().cpu().numpy().tolist()\n",
    "            except:\n",
    "                test_all_preds = test_all_preds + [model_result.detach().cpu().numpy().tolist()]\n",
    "    model.train()\n",
    "\n",
    "    loss_value = np.mean(batch_losses)\n",
    "    valid_loss_value = np.mean(valid_batch_losses)\n",
    "    all_losses.append(loss_value)\n",
    "    all_valid_losses.append(valid_loss_value)\n",
    "    # print('Epoch {} loss: {}'.format(epoch, loss_value))\n",
    "    if valid_loss_value > old_valid_loss:\n",
    "        patience_counter += 1\n",
    "    else:\n",
    "        patience_counter = 0\n",
    "        old_valid_loss = valid_loss_value\n",
    "\n",
    "    if patience_counter > 3:\n",
    "        break\n",
    "\n",
    "    if max_epoch_number < epoch:\n",
    "        break\n",
    "    epoch += 1\n",
    "\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     test_targets_all = []\n",
    "#     test_all_preds = []\n",
    "#     for inputs, targets in test_dataloader:\n",
    "#         inputs, targets = inputs.to(device), targets.to(device)\n",
    "#         model_result = model(inputs).squeeze()\n",
    "#         test_targets_all = test_targets_all + targets.cpu().numpy().tolist()\n",
    "#         try:\n",
    "#             test_all_preds = test_all_preds + model_result.detach().cpu().numpy().tolist()\n",
    "#         except:\n",
    "#             test_all_preds = test_all_preds + [model_result.detach().cpu().numpy().tolist()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Amazon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
